{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723812620.996535    5723 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech\n",
    "\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"\n",
    "\n",
    "audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz = 16000,\n",
    "    language_code=\"en-US\",\n",
    ")\n",
    "\n",
    "response = client.recognize(config = config, audio = audio)\n",
    "\n",
    "# for result in response.results:\n",
    "#     print(\"Transcript: {}\".format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how old is the Brooklyn Bridge'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.results[0].alternatives[0].transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google.generativeai.types.safety_types import HarmBlockThreshold, HarmCategory\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import json\n",
    "from google.cloud import speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: how old is the Brooklyn Bridge\n",
      "Answer: text: \"The Brooklyn Bridge was completed in **1883**, so it\\'s currently **140 years old** (as of 2023). \\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"environments/env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "client = speech.SpeechClient()\n",
    "gcs_uri = env[\"sample_audio_file\"]\n",
    "audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz = 16000,\n",
    "    language_code=\"en-US\",\n",
    ")\n",
    "\n",
    "s2t_response = client.recognize(config = config, audio = audio)\n",
    "\n",
    "vertexai.init(project = env[\"project_id\"], location=env[\"location\"])\n",
    "multimodal_model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "for result in s2t_response.results:\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            result.alternatives[0].transcript\n",
    "        ]\n",
    "    )\n",
    "    print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "    print(\"Answer: {}\".format(response.candidates[0].content.parts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723443168.305417   26301 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: I'm Yusuke, and living in Tokyo, and working as IT engineer at the company.\n",
      "In my free time, I like to go to gym to workout, watching Netfilx, go hiking, and playing video game.\n",
      "Thank you, and nice to meet you.\n",
      "Answer: text: \"Let\\'s take a look at your introduction and make it even better! \\n\\n**Uncorrected Sentence:** I\\'m Yusuke, and living in Tokyo, and working as IT engineer at the company.\\n\\n**Correction:** I\\'m Yusuke, and I live in Tokyo. I work as an IT engineer at [Name of Company].\\n\\n**Uncorrected Sentence:** In my free time, I like to go to gym to workout, watching Netfilx, go hiking, and playing video game.\\n\\n**Correction:**  In my free time, I enjoy going to the gym to work out, watching Netflix, hiking, and playing video games.\\n\\n**Recommended Phrases:** \\n\\n1. **Instead of \\\"Thank you, and nice to meet you,\\\" try:**  \\\"It\\'s a pleasure to meet you!\\\"\\n2. **To add a touch of personality:**  \\\"I\\'m really enjoying life in Tokyo.\\\" \\n3. **To emphasize your interests:** \\\"I\\'m particularly passionate about [mention a specific interest, e.g., hiking in the mountains].\\\"\\n\\n**Revised Introduction:** \\n\\n\\\"Hi, I\\'m Yusuke. I live in Tokyo and work as an IT engineer at [Name of Company]. In my free time, I enjoy going to the gym to work out, watching Netflix, hiking, and playing video games.  It\\'s a pleasure to meet you!\\\" \\n\\nThis revised introduction is more natural-sounding, grammatically correct, and gives the reader a better understanding of who you are and what you enjoy. \\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting, FinishReason\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "import json\n",
    "\n",
    "def generate(project_id, location, human_text):\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    safety_settings = [\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "        ),\n",
    "        SafetySetting(\n",
    "            category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "            threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "        ),\n",
    "    ]\n",
    "    instrcution = \"\"\"\n",
    "            ## Condition\n",
    "            - You are English professional teacher. \n",
    "            - Point out uncorrect word and grammer.\n",
    "            - Generate three to five recommended useful phrase instead of unnatural tone.\n",
    "            \"\"\"\n",
    "    generation_config = {\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "    }\n",
    "\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-001\",\n",
    "        system_instruction=[instrcution]\n",
    "    )\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            human_text\n",
    "        ],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "with open(\"environments/env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "human_text = \"\"\"I'm Yusuke, and living in Tokyo, and working as IT engineer at the company.\n",
    "In my free time, I like to go to gym to workout, watching Netfilx, go hiking, and playing video game.\n",
    "Thank you, and nice to meet you.\"\"\"\n",
    "\n",
    "response = generate(env[\"project_id\"], env[\"location\"], human_text)\n",
    "\n",
    "print(\"Transcript: {}\".format(human_text))\n",
    "print(\"Answer: {}\".format(response.candidates[0].content.parts[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: text: \"## Summary of Student\\'s Mistakes\\n\\nThe student made several grammatical errors throughout the conversation:\\n\\n* **Incorrect verb tense:** He often used the past tense when the present tense was required, like saying \\\"cannot stop to watch\\\" instead of \\\"cannot stop watching\\\" and \\\"is able to prevent\\\" instead of \\\"able to prevent\\\".\\n* **Incorrect word choice:** He misused words like \\\"promote\\\" and \\\"regret\\\" when he meant \\\"encourage\\\" and \\\"ignore\\\".\\n* **Incomplete sentences:** He sometimes left sentences unfinished, such as when discussing the reasons for bullying.\\n\\n## Summary of Teacher\\'s Corrections\\n\\nThe teacher corrected the student\\'s grammar and word choices, highlighting the importance of precision in language. She also clarified the difference between \\\"promoting\\\" and \\\"facilitating,\\\" emphasizing that promoting bullying would be actively encouraging it, while facilitating it would simply make it easier to occur.\\n\\n## Advanced Words and Phrases\\n\\n* **Adolescence:** The period of time between childhood and adulthood.\\n* **Cyberbullying:** Bullying that takes place online.\\n* **Digital literacy:** The ability to use and understand digital technology.\\n* **Socialization:** The process of learning how to interact with others.\\n* **Parental involvement:** The participation of parents in their child\\'s education and upbringing.\\n* **Peer pressure:** The influence of a person\\'s peers to behave in a certain way.\\n* **Cognitive development:** The process of how children\\'s brains develop and change.\\n* **Developmental psychology:** The study of how people change and develop throughout their lives.\\n* **Media literacy:** The ability to access, analyze, evaluate, and create media.\\n* **Digital divide:** The gap between those who have access to digital technology and those who do not.\\n\\nThis conversation is a great example of how a teacher can help a student improve their communication skills, not only by correcting their mistakes but also by introducing new vocabulary and concepts. The student\\'s reflection on bullying in school culture, especially in Korea and Japan, showcases the relevance of these topics in the digital age.  \\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting, FinishReason, Part\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "import json\n",
    "\n",
    "def generate_from_audio(project_id, location, audio_file_uri):\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    instrcution = \"\"\"\n",
    "            ## Condition\n",
    "            - You are English professional.\n",
    "            - Audio's situation is online English conversation class.\n",
    "            - Man voice is student and woman voice is teacher.\n",
    "            - You should summarize student's mistake of grammar and words.\n",
    "            - You should summarize teacher's pointed out.\n",
    "            - Generate advanced words and phrases related with this conversation.\n",
    "            \"\"\"\n",
    "    audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
    "\n",
    "    model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            audio_file,\n",
    "            instrcution,\n",
    "        ],\n",
    "        # generation_config=generation_config,\n",
    "        # safety_settings=safety_settings,\n",
    "        # stream=False,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "with open(\"environments/env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "audio_file_uri = \"gs://english-learning-feedback/first_half.mp3\"\n",
    "\n",
    "response = generate_from_audio(env[\"project_id\"], env[\"location\"], audio_file_uri)\n",
    "\n",
    "print(\"Answer: {}\".format(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 Speaker A Hello.\n",
      "0:03 Speaker B Hi.\n",
      "0:06 Speaker A Hello.\n",
      "0:08 Speaker B Hi.\n",
      "0:11 Speaker A Uh, can you hear me and see me?\n",
      "0:15 Speaker B Yeah, I can hear you but I can't I can't see you.\n",
      "0:24 Speaker A Okay.\n",
      "0:26 Speaker B Uh, one second.\n",
      "0:29 Speaker A Okay.\n",
      "0:35 Speaker A Can you see me now?\n",
      "0:38 Speaker B Yeah, that's fine. Yeah, I'm okay.\n",
      "0:42 Speaker A All right, how are you today?\n",
      "0:46 Speaker B Yeah, I'm I'm good, and uh Yeah. Sorry, I have I have good. Yes.\n",
      "0:58 Speaker A Okay, that's good. Uh, do you want to start with self-introduction?\n",
      "1:06 Speaker B Yes. Uh, I'll let me introduce myself briefly.\n",
      "1:17 Speaker A Okay.\n",
      "1:20 Speaker B Okay. Uh, my name is Yusuke, and now I'm 31 years old and I'm living in Tokyo and working at the company as an IT engineer. And uh, in my free time I like to go to gym to work out. Uh, watching Netflix, go to uh go hiking. And uh, playing video game. So, that's my introduction. Nice to meet you.\n",
      "1:59 Speaker A Thank you. Nice to meet you, too. Thanks for sharing. Um, okay, well, uh, my name is Ray. Uh, I live in Cairo, Egypt and um I teach English full time. Uh, in my free time I like uh to read books, listen to podcasts and watch movies and TV shows and things like that.\n",
      "2:27 Speaker A Mhm.\n",
      "2:29 Speaker A That's all. Thank you.\n",
      "2:32 Speaker B Thank you, too. And nice to meet you again.\n",
      "2:39 Speaker A Nice to meet you. Um, okay, so let's begin with the lesson you chose. What do you want to Mhm. study today?\n",
      "2:53 Speaker B Okay, I will choose the this one.\n",
      "3:06 Speaker A Okay. Nice topic.\n",
      "3:09 Speaker B Thank you. Um, all right. So, let's see. We first one, we want to choose or decide whether you agree or disagree with the statement and then explain why. Okay?\n",
      "3:32 Speaker B Okay, sure.\n",
      "3:34 Speaker A So, first one, Age restrictions should be placed on social media sites.\n",
      "3:42 Speaker B Well, yeah, I agree with this opinion because uh, Hmm. Because of social media sites and application or applications are very addictive for the people, so, kids and uh, children uh cannot uh, stop to watch the the application every time. So, at least I think we need the like uh, time restrictions uh, to watch the and watching these application.\n",
      "4:27 Speaker A Okay. Yes, I agree. So, social media sites are addictive. Yes, that's true. And so, children and adults Mhm. I think both, right? The you said both. Children and adults. Yeah. Yeah. can't seem to stop using them.\n",
      "4:51 Speaker B Yeah, that's right. Yes. Every people cannot stop to watch.\n",
      "5:01 Speaker A Yes. Okay, very good. Well, what do you think about the next one? Age restrictions prevent cyberbullying?\n",
      "5:14 Speaker B Wow. Cyberbullying is a like a bullying, bullying uh through the like uh messenger or some group chat or like that, uh-huh.\n",
      "5:31 Speaker B Well, Hmm. Yeah, partially partially age restriction uh, able is able to prevent the bullying, Hmm. cyberbullying. Um, my the reason is uh, the reason of the partially uh, That's uh, how can I say this one. Uh, Well, the human in my opinion, human being uh, cannot stop bullying somebody. So, I think uh, yeah, age restrictions uh I think uh, one of the Hmm. solution to stop bullying, but uh, I think people can find uh, another way to bullying. Way, another way of bullying somebody.\n",
      "6:34 Speaker A Yes.\n",
      "6:36 Speaker B That's why partially uh, preventing the bullying partially Yes. but uh, I think uh, we have to find another way to Hmm. restrict bullying.\n",
      "7:05 Speaker A Mhm, mhm.\n",
      "7:09 Speaker B Yes, maybe.\n",
      "7:15 Speaker A Oh, thank you so much.\n",
      "7:17 Speaker B You're welcome.\n",
      "7:20 Speaker A Yeah. So, You've you've made a good point. So, you think that even if you put age restrictions on on the internet Mhm. then people will just bully through another form, not the internet.\n",
      "7:44 Speaker B Yes, that's right.\n",
      "7:48 Speaker A Yeah. Yeah. That's That's good. Mostly mostly children?\n",
      "7:58 Speaker B Yeah. Yes. Yes.\n",
      "8:03 Speaker A So, I I'm not familiar with the school culture in Japan. Mhm. So, I know that because I'm familiar with Korean culture more, I know there is a lot of bullying in Korean schools. Like, this is uh, almost like a a known fact there. Mhm. So, is it the same in Japan or is it different?\n",
      "8:37 Speaker B Wow. Yeah, it's same almost same situation as the Korea. Mhm. Because uh, I don't I don't know why. It's uh, It's how can I say? Hmm. Due to the personality of nationality of the Japanese, or not sure but uh, I I've often hard that the the Hmm. how can I say? Uh, wise Hmm. technology advances, like a smartphone, internet, uh, social network service. Uh, promote not promote Encourage? Yeah, encourage, yes, encourage the children's bullying, like uh, uh, for example, forget. Regret, not regret. Uh, ignore, yes, ignoring the people, you know, the people who is in same group chat.\n",
      "9:48 Speaker A  Oh, okay.\n",
      "9:52 Speaker B toxic words for the children, not children, for someone. So, and by the way, I'm curious uh, about uh, where where did you get this information, like uh, the Korea is a Korea has a bullying.\n",
      "10:10 Speaker A Right. Well, because, so, I have many sources. First of all, I'm interested in Korean culture. Mhm. Uh, so, I do that. But, also, my uh brother-in-law is Korean. Mhm. So, uh yeah, so, we we talk about different topics and that sometimes comes up. You know, the whole uh, you know, we talk about different cultures and so he tells us about the Korean culture. And so, that's why I'm familiar with it a little bit. \n",
      "10:54 Speaker B Oh, that makes sense. So, you have the many sources uh, of the Korean culture. I see I see. That's great.\n",
      "11:07 Speaker A Yeah.\n",
      "11:11 Speaker A Um, okay. So, but, this was a very good point you made about the technological advances. So, I would say that it facilitates them, not encourages, facilitates. It makes it easier for people to bully each other.\n",
      "11:34 Speaker B Oh, I see. Facilitate bullying, uh-huh. So, promoting is uh, also a bit different.\n",
      "11:45 Speaker A Yeah. So, promoting means I am asking you, hey, it's good time to go bully your friends, so, go ahead bully your friends today. That's promoting. Promote is positive meaning.\n",
      "12:02 Speaker B Positive. Yes. Mhm. Mhm. I see. I see. \n",
      "12:10 Speaker A Okay. Thank you so much. Facilitate bullying.\n",
      "12:15 Speaker B Yeah. Yeah, I remember that.\n",
      "12:19 Speaker A Good. Thank you. Um, okay. Let's move to number three. The time that children spend on social networking sites should be supervised by parents.\n",
      "12:36 Speaker B Wow. I see. Okay. Yeah. Wow. I I agree with the the supervising the the time, Hmm. uh, by the parents. Yeah, because uh, as we discussed uh before uh, that's uh children cannot uh, stop, Hmm. cannot how can I say? Cannot fight with the motivation, so, they're how can I say? The motivation which is uh, which want to spend time uh, on the internet or YouTube or something something like that. Mhm. So, because uh I have a nephew, Mhm. yes nephew, yes. I have a nephew and uh, he is uh, now \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "# TODO(developer): Update and un-comment below lines\n",
    "# project_id = \"PROJECT_ID\"\n",
    "\n",
    "vertexai.init(project=\"ksst-genai-app\", location=\"asia-northeast1\")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Can you transcribe this interview, in the format of timecode, speaker, caption.\n",
    "Use speaker A, speaker B, etc. to identify speakers.\n",
    "\"\"\"\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# ## Condition\n",
    "# - You are English professional.\n",
    "# - Audio's situation is online English conversation class.\n",
    "# - Man voice is student and woman voice is teacher.\n",
    "# - You should summarize student's mistake of grammar and words.\n",
    "# - You should summarize teacher's pointed out.\n",
    "# - Generate advanced words and phrases related with this conversation.\n",
    "# \"\"\"\n",
    "\n",
    "audio_file_uri = \"gs://english-learning-feedback/first_half.mp3\"\n",
    "audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='second_half.mp3'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_file(\"data/lesson.webm\")\n",
    "\n",
    "# Calculate the half point of the audio\n",
    "half_point = len(audio) // 2\n",
    "\n",
    "# Split the audio into two halves\n",
    "first_half = audio[:half_point]\n",
    "second_half = audio[half_point:]\n",
    "\n",
    "# Export the two halves as MP3 files\n",
    "first_half.export(\"first_half.mp3\", format=\"mp3\")\n",
    "second_half.export(\"second_half.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
